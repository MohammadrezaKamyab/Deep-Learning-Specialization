{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e70d0751-9ca8-47b8-8b62-ab594c179dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples : m_train =  209\n",
      "Number of Test Examples : m_test =  50\n",
      "Height/Width of each image : num_px =  64\n",
      "Training_set_X shape =  (209, 64, 64, 3)\n",
      "Training_set_y shape =  (1, 209)\n",
      "Test_set_X shape =  (50, 64, 64, 3)\n",
      "Test_set_y shape =  (1, 50)\n",
      "X_train shape =  (12288, 209)\n",
      "y_train shape =  (1, 209)\n",
      "X_test shape =  (12288, 50)\n",
      "y_test shape =  (1, 50)\n",
      "Train Accuracy = 99.04306220095694 %\n",
      "Test Accuracy = 70.0 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import h5py\n",
    "from scipy import ndimage\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()\n",
    "\n",
    "## **Preprocessing**\n",
    "\n",
    "### 1. Overview\n",
    "\n",
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "\n",
    "print(\"Number of Training Examples : m_train = \", str(m_train))\n",
    "print(\"Number of Test Examples : m_test = \", str(m_test))\n",
    "print(\"Height/Width of each image : num_px = \" , str(num_px))\n",
    "print(\"Training_set_X shape = \", str(train_set_x_orig.shape))\n",
    "print(\"Training_set_y shape = \", str(train_set_y.shape))\n",
    "print(\"Test_set_X shape = \", str(test_set_x_orig.shape))\n",
    "print(\"Test_set_y shape = \", str(test_set_y.shape))\n",
    "\n",
    "### 2. Reshape\n",
    "\n",
    "X_train = train_set_x_orig.reshape(m_train, -1).T\n",
    "X_test = test_set_x_orig.reshape(m_test, -1).T\n",
    "\n",
    "print(\"X_train shape = \", str(X_train.shape))\n",
    "print(\"y_train shape = \", str(train_set_y.shape))\n",
    "print(\"X_test shape = \", str(X_test.shape))\n",
    "print(\"y_test shape = \", str(test_set_y.shape))\n",
    "\n",
    "## 3. Rescale\n",
    "\n",
    "## It is simpler and more convinient and works as well as standardization (z-score normalization) to just divide\n",
    "# the rows by 255\n",
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255\n",
    "\n",
    "## **Building Part of The cat Classifier**\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        z ndarray (1, m) -- Linear Part of the model\n",
    "    return :\n",
    "        a ndarray (1,m) -- prediction for each training Input\n",
    "    \"\"\"\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def initialize_paramters(dim):\n",
    "    \"\"\"\n",
    "    args : \n",
    "        dim scalar : number of features = width_image * height_image * depth_image\n",
    "    return : \n",
    "        w ndarray (n , 1) : initialzed weights for each feature\n",
    "        b float : bias\n",
    "    \"\"\"\n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0.0\n",
    "    return w, b\n",
    "\n",
    "def propagate (w, b, X, y):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        w ndarray (n , 1) -- weights paramters of size (width_px * height_px * 3, 1)\n",
    "        b scalar (float) -- bias\n",
    "        X ndarray (n , m) -- Feature Vector x with (width_px * height_px * 3, 1)\n",
    "        y ndarray (1, m) -- true labels for all training example\n",
    "    returns :\n",
    "    grads -- dictionary containing the gradients of weights and bias\n",
    "        (dw -- gradient of the loss with respect to w , thus the same shape as w)\n",
    "        (db -- gradient of the loss with respect to b , thus the same shape as b)\n",
    "    cost -- negative log-likelood cost for logistic regression\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    # compute cost \n",
    "    z = np.dot(w.T, X) + b\n",
    "    a = sigmoid(z)\n",
    "    loss = y * np.log(a) + (1 - y) * np.log(1 - a)\n",
    "    cost = (-1/m) * np.sum(loss)\n",
    "\n",
    "    # compute gradient\n",
    "    dz = a - y\n",
    "    dw = (1/m) * np.dot(X, dz.T)\n",
    "    db = (1/m) * np.sum(dz)\n",
    "\n",
    "    grads = {\n",
    "        \"dw\" : dw,\n",
    "        \"db\" : db\n",
    "    }\n",
    "\n",
    "    return grads, cost\n",
    "\n",
    "def optimizer(w_init,b_init, X, y, iterations=100, learning_rate=0.009, print_cost=False,tolerance=1e-8):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    params -- dictionary containing weights w & b bias\n",
    "    grads  -- dictinary containing gradients of weights and bias with respect to cost function\n",
    "    cost   -- list of all cost computed during the optimization - this will be used to plot learning curves\n",
    "    \"\"\"\n",
    "    w = copy.deepcopy(w_init)\n",
    "    b = copy.deepcopy(b_init)\n",
    "    costs = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        grads , cost = propagate(w,b,X,y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "        if print_cost:\n",
    "            print(f\"Iteration {i:5d} : Cost = {cost : 8.4f}\")\n",
    "\n",
    "        if len(costs) >= 2 and abs(costs[-1] - costs[-2]) < tolerance:\n",
    "            print(f\"Converges at {i : 5d}\")\n",
    "            break\n",
    "\n",
    "    params = {\"w\":w,\n",
    "            \"b\":b}\n",
    "    grads = {\"dw\" : dw,\n",
    "             \"db\" : db}\n",
    "    \n",
    "    return params, grads, cost\n",
    "        \n",
    "\n",
    "def predict (w, b , X):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    w -- weights, a numpy array of size (lenth_px * height_px * 3, 1)\n",
    "    b -- bias , a scalar (float)\n",
    "    X -- Input Matrix, a Matrix of size (n , m)\n",
    "\n",
    "    returns:\n",
    "    Y_prediction -- Prediction (0 or 1), a numpy row vector of size (1 * m)\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0, i] >= 0.5:\n",
    "            Y_prediction[0, i] = 1\n",
    "        else:\n",
    "            Y_prediction[0, i] = 0\n",
    "    return Y_prediction\n",
    "\n",
    "## **Define the Model**\n",
    "\n",
    "def model (X_train, y_train, X_test, y_test, number_iteration=2000, learning_rate=0.5, print_cost=False):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    d -- information about the model (w, b, Y_prediction_train, Y_predition_test, cost, learning_rate, number_iteration)\n",
    "    \"\"\"\n",
    "    w, b = initialize_paramters(X_train.shape[0])\n",
    "    params, grads, costs = optimizer(w,b,X_train, y_train, number_iteration, learning_rate)\n",
    "    w = params.get('w')\n",
    "    b = params.get('b')\n",
    "    Y_prediction_train = predict(w,b,X_train)\n",
    "    Y_prediction_test = predict(w,b, X_test)\n",
    "\n",
    "    if print_cost:\n",
    "        print(\"Train Accuracy = {} %\".format(100 - np.mean(np.abs(Y_prediction_train - y_train)) * 100 ))\n",
    "        print(\"Test Accuracy = {} %\".format(100 - np.mean(np.abs(Y_prediction_test - y_test)) * 100 ))\n",
    "\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": number_iteration}\n",
    "    \n",
    "    return d\n",
    "\n",
    "logistic_regression_model = model(X_train_scaled, train_set_y, X_test_scaled, test_set_y, number_iteration=2000, learning_rate=0.005, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b1f3e-d3ba-4a3d-b204-443998e890d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
